{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformation in ML.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1GRqDaVzD99"
      },
      "source": [
        "**Applying data transformations**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDOap7vBzvBO"
      },
      "source": [
        "The different kind of transformations do, let’s apply them using\n",
        "scikit-learn.\n",
        "We will use the cancer dataset, \n",
        "Preprocessing methods like\n",
        "the scalers are usually applied before applying a supervised machine learning algo‐\n",
        "rithm. As an example, say we want to apply the kernel SVM (SVC) to the cancer data‐\n",
        "set, and use MinMaxScaler for preprocessing the data. We start by loading and\n",
        "splitting our dataset into a training set and a test set. We need a separate training and\n",
        "test set to evaluate the supervised model we will build after the preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5fL-1-6zHTC",
        "outputId": "82296c61-46bb-4bee-fe0f-f89f57a2acf6"
      },
      "source": [
        "# Importing the dataset\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import numpy as np\n",
        "\n",
        "#Spliting the dataset into training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "cancer = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,\n",
        " random_state=1)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(426, 30)\n",
            "(143, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPjrUBsu4yEj"
      },
      "source": [
        "As a reminder, the data contains 150 data points, each represented by four measure‐\n",
        "ments. We split the dataset into 112 samples for the training set and 38 samples for\n",
        "the test set.\n",
        "\n",
        "As with the supervised models we built earlier, we first import the class implementing\n",
        "the preprocessing, and then instantiate it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDHIp06u4kzX"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCseQxvS5Daq"
      },
      "source": [
        "Unsupervised Learning and Preprocessing\n",
        "We then fit the scaler using the fit method, applied to the training data. For the Min\n",
        "MaxScaler, the fit method computes the minimum and maximum value of each fea‐\n",
        "ture on the training set. In contrast to the classifiers and regressors of chapter 2, the\n",
        "scaler is only provided with the data X_train when fit is called, and y_train is not\n",
        "used:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka56QLbN5HjK",
        "outputId": "5a951793-ef8c-4f1d-c688-b15056a11d44"
      },
      "source": [
        "scaler.fit(X_train)\n",
        "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zdMOlqJ5US5"
      },
      "source": [
        "To apply the transformation that we just learned, that is, to actually scale the training\n",
        "data, we use the transform method of the scaler. The transform method is used in\n",
        "scikit-learn whenever a model returns a new representation of the data:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxE7h4fu5uAq",
        "outputId": "9a26ff77-747e-4382-aed8-a044db5174cf"
      },
      "source": [
        "np.set_printoptions(suppress=True, precision=2)\n",
        "# transform data\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "# print data set properties before and after scaling\n",
        "print(\"transformed shape: %s\" % (X_train_scaled.shape,))\n",
        "print(\"per-feature minimum before scaling:\\n %s\" % X_train.min(axis=0))\n",
        "print(\"per-feature maximum before scaling:\\n %s\" % X_train.max(axis=0))\n",
        "print(\"per-feature minimum after scaling:\\n %s\" % X_train_scaled.min(axis=0))\n",
        "print(\"per-feature maximum after scaling:\\n %s\" % X_train_scaled.max(axis=0))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformed shape: (426, 30)\n",
            "per-feature minimum before scaling:\n",
            " [  6.98   9.71  43.79 143.5    0.05   0.02   0.     0.     0.11   0.05\n",
            "   0.12   0.36   0.76   6.8    0.     0.     0.     0.     0.01   0.\n",
            "   7.93  12.02  50.41 185.2    0.07   0.03   0.     0.     0.16   0.06]\n",
            "per-feature maximum before scaling:\n",
            " [  28.11   39.28  188.5  2501.      0.16    0.29    0.43    0.2     0.3\n",
            "    0.1     2.87    4.88   21.98  542.2     0.03    0.14    0.4     0.05\n",
            "    0.06    0.03   36.04   49.54  251.2  4254.      0.22    0.94    1.17\n",
            "    0.29    0.58    0.15]\n",
            "per-feature minimum after scaling:\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0.]\n",
            "per-feature maximum after scaling:\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBrCkG3T55Hg"
      },
      "source": [
        "The transformed data has the same shape as the original data - the features are simply\n",
        "shifted and scaled.\n",
        "You can see that all of the feature are now between zero and one, as desired.\n",
        "To apply the SVM to the scaled data, we also need to transform the test set. This is\n",
        "done by again calling the transform method, this time on X_test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BF-5tJo56eO",
        "outputId": "0fb2bb86-0261-404c-a18a-9f766fb5be1d"
      },
      "source": [
        "# transform test data\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# print test data properties after scaling\n",
        "print(\"per-feature minimum after scaling: %s\" % X_test_scaled.min(axis=0))\n",
        "print(\"per-feature maximum after scaling: %s\" % X_test_scaled.max(axis=0))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "per-feature minimum after scaling: [ 0.03  0.02  0.03  0.01  0.14  0.04  0.    0.    0.15 -0.01 -0.    0.01\n",
            "  0.    0.    0.04  0.01  0.    0.   -0.03  0.01  0.03  0.06  0.02  0.01\n",
            "  0.11  0.03  0.    0.   -0.   -0.  ]\n",
            "per-feature maximum after scaling: [0.96 0.82 0.96 0.89 0.81 1.22 0.88 0.93 0.93 1.04 0.43 0.5  0.44 0.28\n",
            " 0.49 0.74 0.77 0.63 1.34 0.39 0.9  0.79 0.85 0.74 0.92 1.13 1.07 0.92\n",
            " 1.21 1.63]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zswb7_uV6Ii3"
      },
      "source": [
        "Maybe somewhat surprisingly, you can see that for the test set, after scaling, the mini‐\n",
        "mum and maximum are not zero and one. Some of the features are even outside the\n",
        "0-1 range!\n",
        "The explanation is that the MinMaxScaler (and all the other scalers) always applies\n",
        "exactly the same transformation to the training and the test set. So the transform\n",
        "method always subtracts the training set minimum, and divides by the training set\n",
        "range, which might be different than the minimum and range for the test set"
      ]
    }
  ]
}